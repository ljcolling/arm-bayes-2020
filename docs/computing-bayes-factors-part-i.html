<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Computing Bayes factors Part I | Bayesian Data Analysis</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Computing Bayes factors Part I | Bayesian Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Computing Bayes factors Part I | Bayesian Data Analysis" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Lincoln Colling" />


<meta name="date" content="2020-04-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="choosing-priors-part-i.html"/>
<link rel="next" href="computing-bayes-factors-part-ii.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#introduction"><i class="fa fa-check"></i>Introduction</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="the-p-value.html"><a href="the-p-value.html"><i class="fa fa-check"></i><b>1</b> The <em>p</em> value</a><ul>
<li class="chapter" data-level="1.1" data-path="the-p-value.html"><a href="the-p-value.html#probability"><i class="fa fa-check"></i><b>1.1</b> Probability</a></li>
<li class="chapter" data-level="1.2" data-path="the-p-value.html"><a href="the-p-value.html#probability-and-p-values"><i class="fa fa-check"></i><b>1.2</b> Probability and <em>p</em> values</a><ul>
<li class="chapter" data-level="1.2.1" data-path="the-p-value.html"><a href="the-p-value.html#understanding-the-p-through-simulation"><i class="fa fa-check"></i><b>1.2.1</b> Understanding the <em>p</em> through simulation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="the-p-value.html"><a href="the-p-value.html#interim-summary"><i class="fa fa-check"></i><b>1.3</b> Interim summary</a></li>
<li class="chapter" data-level="1.4" data-path="the-p-value.html"><a href="the-p-value.html#a-short-note-on-confidence-intervals"><i class="fa fa-check"></i><b>1.4</b> A short note on confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="criticisms-of-p-values.html"><a href="criticisms-of-p-values.html"><i class="fa fa-check"></i><b>2</b> Criticisms of <em>p</em> values</a><ul>
<li class="chapter" data-level="2.1" data-path="criticisms-of-p-values.html"><a href="criticisms-of-p-values.html#same-measurements-from-different-devices"><i class="fa fa-check"></i><b>2.1</b> Same measurements from different devices</a></li>
<li class="chapter" data-level="2.2" data-path="criticisms-of-p-values.html"><a href="criticisms-of-p-values.html#the-universe-of-possible-events"><i class="fa fa-check"></i><b>2.2</b> The universe of possible events</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-evidential-alternative-to-p-values.html"><a href="the-evidential-alternative-to-p-values.html"><i class="fa fa-check"></i><b>3</b> The evidential alternative to <em>p</em> values</a><ul>
<li class="chapter" data-level="3.1" data-path="the-evidential-alternative-to-p-values.html"><a href="the-evidential-alternative-to-p-values.html#a-theory-of-statistical-evidence"><i class="fa fa-check"></i><b>3.1</b> A theory of statistical evidence</a><ul>
<li class="chapter" data-level="3.1.1" data-path="the-evidential-alternative-to-p-values.html"><a href="the-evidential-alternative-to-p-values.html#some-features-of-likelihoods"><i class="fa fa-check"></i><b>3.1.1</b> Some features of likelihoods</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-evidential-alternative-to-p-values.html"><a href="the-evidential-alternative-to-p-values.html#likelihoods-and-statistical-evidence"><i class="fa fa-check"></i><b>3.1.2</b> Likelihoods and statistical evidence</a></li>
<li class="chapter" data-level="3.1.3" data-path="the-evidential-alternative-to-p-values.html"><a href="the-evidential-alternative-to-p-values.html#are-all-sub-hypotheses-equal"><i class="fa fa-check"></i><b>3.1.3</b> Are all sub-hypotheses equal?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bayes-rule.html"><a href="bayes-rule.html"><i class="fa fa-check"></i><b>4</b> Bayes rule</a><ul>
<li class="chapter" data-level="4.1" data-path="bayes-rule.html"><a href="bayes-rule.html#what-is-bayes-rule"><i class="fa fa-check"></i><b>4.1</b> What is Bayes rule</a><ul>
<li class="chapter" data-level="4.1.1" data-path="bayes-rule.html"><a href="bayes-rule.html#conditional-probability-form"><i class="fa fa-check"></i><b>4.1.1</b> Conditional probability form</a></li>
<li class="chapter" data-level="4.1.2" data-path="bayes-rule.html"><a href="bayes-rule.html#proportional-form"><i class="fa fa-check"></i><b>4.1.2</b> Proportional form</a></li>
<li class="chapter" data-level="4.1.3" data-path="bayes-rule.html"><a href="bayes-rule.html#ratio-form"><i class="fa fa-check"></i><b>4.1.3</b> Ratio form</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="bayes-rule.html"><a href="bayes-rule.html#bayes-factor"><i class="fa fa-check"></i><b>4.2</b> Bayes factor</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="choosing-priors-part-i.html"><a href="choosing-priors-part-i.html"><i class="fa fa-check"></i><b>5</b> Choosing priors Part I</a><ul>
<li class="chapter" data-level="5.1" data-path="choosing-priors-part-i.html"><a href="choosing-priors-part-i.html#priors-with-specific-mathematical-properties"><i class="fa fa-check"></i><b>5.1</b> Priors with specific mathematical properties</a></li>
<li class="chapter" data-level="5.2" data-path="choosing-priors-part-i.html"><a href="choosing-priors-part-i.html#priors-that-reflect-ignorance"><i class="fa fa-check"></i><b>5.2</b> Priors that reflect ignorance</a></li>
<li class="chapter" data-level="5.3" data-path="choosing-priors-part-i.html"><a href="choosing-priors-part-i.html#priors-that-reflect-our-beliefs-about-the-world."><i class="fa fa-check"></i><b>5.3</b> Priors that reflect our beliefs about the world.</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="computing-bayes-factors-part-i.html"><a href="computing-bayes-factors-part-i.html"><i class="fa fa-check"></i><b>6</b> Computing Bayes factors Part I</a><ul>
<li class="chapter" data-level="6.1" data-path="computing-bayes-factors-part-i.html"><a href="computing-bayes-factors-part-i.html#priors-on-effect-sizes"><i class="fa fa-check"></i><b>6.1</b> Priors on effect sizes</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="computing-bayes-factors-part-ii.html"><a href="computing-bayes-factors-part-ii.html"><i class="fa fa-check"></i><b>7</b> Computing Bayes factors Part II</a><ul>
<li class="chapter" data-level="7.1" data-path="computing-bayes-factors-part-ii.html"><a href="computing-bayes-factors-part-ii.html#priors-on-raw-effects"><i class="fa fa-check"></i><b>7.1</b> Priors on raw effects</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/ljcolling/notebooks" target="blank">View on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="computing-bayes-factors-part-i" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Computing Bayes factors Part I</h1>
<p>We’ve already worked through computing a <strong>Bayes factor</strong> for our coin flip example. In this section, we’re going to work through computing BFs for the kinds of problems you ordinarily encounter in psychology. We’re going to start simple, and look at the kind of problems that you might have answered with a <em>t</em>-test.</p>
<p>But before that, we need to go back to our equation for <span class="math inline">\(\mathcal{M}_H\)</span>:</p>
<p><span class="math display">\[\mathcal{M}_H = \sum_{i=1}^{n}\mathcal{L}_H(\theta_i|\mathbf{y})\cdot{}p(\theta_i)\]</span></p>
<p>This equation worked fine for our coin flip example. We had a discrete number of parameter values (or sub-hypotheses) so we could just average (i.e., sum and then multiply by <span class="math inline">\(\frac{1}{n}\)</span>) their likelihood values. But now we’re going to start working with problems where our sub-hypotheses are going to span a continuous range. So we’ll just update our equation to reflect this. The equation “works” the same way, but it will look a little different. Our new equation is as follows:</p>
<p><span class="math display">\[\mathcal{M}_H = \int_{\theta\in\Theta_H}\mathcal{L}_H(\theta|\mathbf{y})p(\theta)d\theta\]</span></p>
<p>The equation still does the same thing—that is, it represents a continuous average of likelihoods, over the entire parameter space (<span class="math inline">\(\Theta_H\)</span>), with the prior (<span class="math inline">\(p\)</span>) serving as the weights.</p>
<div id="priors-on-effect-sizes" class="section level2">
<h2><span class="header-section-number">6.1</span> Priors on effect sizes</h2>
<p>We’ll start with a problem that’s outlined in <a href="http://pcl.missouri.edu/sites/default/files/Rouder.bf_.pdf">Rouder et al (2009, pg 232)</a>. We’ll work through recreating the analysis, so that we can better understand how it works and what it means.</p>
<p>Rouder et al (2009) reports some summary stats from Grider and Malmberg (2008). Grider and Malmberg (2008) ran a study assessing whether participants were bettter at remembering emotional words or netural words. Usually, we’re not working off summary stats, so we’ll use those summary stats to generate some <em>synthetic</em> data that matches those characteristics.</p>
<p>Grider and Malmberg claimed that emotional words were remembered better than neutral words:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="computing-bayes-factors-part-i.html#cb62-1"></a><span class="co"># 1</span></span>
<span id="cb62-2"><a href="computing-bayes-factors-part-i.html#cb62-2"></a></span>
<span id="cb62-3"><a href="computing-bayes-factors-part-i.html#cb62-3"></a><span class="co"># lets generate some data to work with because usually we work with raw data and not summary stats</span></span>
<span id="cb62-4"><a href="computing-bayes-factors-part-i.html#cb62-4"></a></span>
<span id="cb62-5"><a href="computing-bayes-factors-part-i.html#cb62-5"></a><span class="co"># statistics reported by Grider and Malmberg (2008) in Rouder et al (2009, pg 232)</span></span>
<span id="cb62-6"><a href="computing-bayes-factors-part-i.html#cb62-6"></a></span>
<span id="cb62-7"><a href="computing-bayes-factors-part-i.html#cb62-7"></a><span class="co"># reported values!</span></span>
<span id="cb62-8"><a href="computing-bayes-factors-part-i.html#cb62-8"></a>sample_size =<span class="st"> </span><span class="dv">80</span></span>
<span id="cb62-9"><a href="computing-bayes-factors-part-i.html#cb62-9"></a>netural_words =<span class="st"> </span><span class="fl">0.76</span></span>
<span id="cb62-10"><a href="computing-bayes-factors-part-i.html#cb62-10"></a>positive_words =<span class="st"> </span><span class="fl">0.80</span></span>
<span id="cb62-11"><a href="computing-bayes-factors-part-i.html#cb62-11"></a>t_stat =<span class="st"> </span><span class="fl">2.24</span></span>
<span id="cb62-12"><a href="computing-bayes-factors-part-i.html#cb62-12"></a></span>
<span id="cb62-13"><a href="computing-bayes-factors-part-i.html#cb62-13"></a><span class="co"># calculate the rest from the reported values!</span></span>
<span id="cb62-14"><a href="computing-bayes-factors-part-i.html#cb62-14"></a>mean_of_difference =<span class="st"> </span>positive_words <span class="op">-</span><span class="st"> </span>netural_words</span>
<span id="cb62-15"><a href="computing-bayes-factors-part-i.html#cb62-15"></a>sd_of_difference =<span class="st"> </span>(mean_of_difference <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(sample_size)) <span class="op">/</span><span class="st"> </span>t_stat</span>
<span id="cb62-16"><a href="computing-bayes-factors-part-i.html#cb62-16"></a></span>
<span id="cb62-17"><a href="computing-bayes-factors-part-i.html#cb62-17"></a><span class="co"># generate some data that matches those characteristics</span></span>
<span id="cb62-18"><a href="computing-bayes-factors-part-i.html#cb62-18"></a></span>
<span id="cb62-19"><a href="computing-bayes-factors-part-i.html#cb62-19"></a>g_m_<span class="dv">2008</span>_data =<span class="st"> </span>mean_of_difference <span class="op">+</span><span class="st"> </span>sd_of_difference <span class="op">*</span><span class="st"> </span><span class="kw">scale</span>(<span class="kw">rnorm</span>(<span class="dt">n =</span> sample_size, <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb62-20"><a href="computing-bayes-factors-part-i.html#cb62-20"></a></span>
<span id="cb62-21"><a href="computing-bayes-factors-part-i.html#cb62-21"></a><span class="kw">glue</span>(<span class="st">&quot;Accuracy for positive words was {positive_words}  </span></span>
<span id="cb62-22"><a href="computing-bayes-factors-part-i.html#cb62-22"></a><span class="st">Accuracy for neutral words was {netural_words}&quot;</span>)</span></code></pre></div>
<p>Accuracy for positive words was 0.8<br />
Accuracy for neutral words was 0.76</p>
<p>Since we now have “raw” data, we might as well draw a few plots.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="computing-bayes-factors-part-i.html#cb63-1"></a><span class="co"># 2</span></span>
<span id="cb63-2"><a href="computing-bayes-factors-part-i.html#cb63-2"></a></span>
<span id="cb63-3"><a href="computing-bayes-factors-part-i.html#cb63-3"></a><span class="co"># lets take a look at the data</span></span>
<span id="cb63-4"><a href="computing-bayes-factors-part-i.html#cb63-4"></a></span>
<span id="cb63-5"><a href="computing-bayes-factors-part-i.html#cb63-5"></a>plot1 =<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="st">&quot;neutral&quot;</span>,<span class="st">&quot;positive&quot;</span>), <span class="dt">y =</span> <span class="kw">c</span>(netural_words,positive_words))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb63-6"><a href="computing-bayes-factors-part-i.html#cb63-6"></a><span class="kw">geom_col</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>(<span class="dv">16</span>) <span class="op">+</span><span class="st"> </span><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;recall accuracy&quot;</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb63-7"><a href="computing-bayes-factors-part-i.html#cb63-7"></a><span class="kw">scale_x_discrete</span>(<span class="dt">name =</span> <span class="st">&quot;valence&quot;</span>)</span>
<span id="cb63-8"><a href="computing-bayes-factors-part-i.html#cb63-8"></a>plot2 =<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">mapping =</span> (<span class="kw">aes</span>(<span class="dt">x =</span> g_m_<span class="dv">2008</span>_data))) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb63-9"><a href="computing-bayes-factors-part-i.html#cb63-9"></a><span class="kw">scale_x_continuous</span>(<span class="st">&quot;difference in accuracy&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>(<span class="dv">16</span>)</span>
<span id="cb63-10"><a href="computing-bayes-factors-part-i.html#cb63-10"></a>plot1 <span class="op">+</span><span class="st"> </span>plot2 <span class="op">+</span><span class="st"> </span><span class="kw">plot_annotation</span>(<span class="dt">tag_levels =</span> <span class="st">&quot;A&quot;</span>)</span></code></pre></div>
<p><img src="book_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<p>We’ll now move on to the analysis. We’ll do this in <strong>3</strong> steps. In step <strong>1</strong>, we’ll just run a <em>t</em> test like Grider and Malmberg (2008) did. In step <strong>2</strong>, we’ll run the <strong>default Bayes factor</strong> <em>t</em>-test using the <strong>R</strong> package developed Rouder et al. But so that we can <strong>really</strong> understand what’s going on, in step <strong>3</strong>, we’re going to calculate our own <strong>Bayes factor</strong> using the stuff we’ve learned up until now!</p>
<ol style="list-style-type: decimal">
<li>First do a <em>t</em> test and report the results!</li>
</ol>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="computing-bayes-factors-part-i.html#cb64-1"></a><span class="co"># 3</span></span>
<span id="cb64-2"><a href="computing-bayes-factors-part-i.html#cb64-2"></a></span>
<span id="cb64-3"><a href="computing-bayes-factors-part-i.html#cb64-3"></a><span class="co"># lets do some analysis!</span></span>
<span id="cb64-4"><a href="computing-bayes-factors-part-i.html#cb64-4"></a></span>
<span id="cb64-5"><a href="computing-bayes-factors-part-i.html#cb64-5"></a><span class="co"># first, lets run a *t* test like Grider and Malmberg (2008)</span></span>
<span id="cb64-6"><a href="computing-bayes-factors-part-i.html#cb64-6"></a>t_test_results =<span class="st"> </span><span class="kw">t.test</span>(g_m_<span class="dv">2008</span>_data)</span>
<span id="cb64-7"><a href="computing-bayes-factors-part-i.html#cb64-7"></a></span>
<span id="cb64-8"><a href="computing-bayes-factors-part-i.html#cb64-8"></a><span class="co"># now we&#39;ll format them nicely!</span></span>
<span id="cb64-9"><a href="computing-bayes-factors-part-i.html#cb64-9"></a>t_test_results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb64-10"><a href="computing-bayes-factors-part-i.html#cb64-10"></a>glue<span class="op">::</span><span class="kw">glue_data</span>(<span class="st">&quot;*t* ({parameter}) = {round(statistic,2)}, *p* = {round(p.value,2)}&quot;</span>)</span></code></pre></div>
<p><em>t</em> (79) = 2.24, <em>p</em> = 0.03</p>
<ol start="2" style="list-style-type: decimal">
<li>Now use an R package to calculate a <strong>Bayes factor</strong>:</li>
</ol>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="computing-bayes-factors-part-i.html#cb65-1"></a><span class="co"># 4</span></span>
<span id="cb65-2"><a href="computing-bayes-factors-part-i.html#cb65-2"></a></span>
<span id="cb65-3"><a href="computing-bayes-factors-part-i.html#cb65-3"></a><span class="co"># now run a BF analysis with &quot;default&quot; priors</span></span>
<span id="cb65-4"><a href="computing-bayes-factors-part-i.html#cb65-4"></a></span>
<span id="cb65-5"><a href="computing-bayes-factors-part-i.html#cb65-5"></a>store_bought_bf  =<span class="st"> </span>BayesFactor<span class="op">::</span><span class="kw">ttestBF</span>(g_m_<span class="dv">2008</span>_data, <span class="dt">rscale =</span> <span class="dv">1</span>)</span>
<span id="cb65-6"><a href="computing-bayes-factors-part-i.html#cb65-6"></a>store_bought_bf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span>glue<span class="op">::</span><span class="kw">glue_data</span>(<span class="st">&quot;JZS Bayes factor = {round(BF01,2)}&quot;</span>)</span></code></pre></div>
<p>JZS Bayes factor = 1.02</p>
<ol start="3" style="list-style-type: decimal">
<li>Let’s try figure out where that number comes from and what it means by reverse engineering it!</li>
</ol>
<p>So far we’ve learned that we need 4 things to <strong>build a BF</strong>
1. we’ll need to choose a <strong>parameter</strong> to make inferences about
2. We need a <em>likelihood function</em> which will describe how likely different <strong>parameter</strong> values are, given our data
3. We need a model of our Model 1 (we can call it <span class="math inline">\(\mathcal{H}_0\)</span>)
4. We need a model of our Model 2 (we can call it <span class="math inline">\(\mathcal{H}_1\)</span>)</p>
<p>What do Rouder et al have to say about <strong>their</strong> choices?</p>
<p>Rouder et al choose to make inferences about standardised effect sizes (e.g., <span class="math inline">\(\delta\)</span>). This is probably a good choice, because standardised effect sizes are easily compared. However, raw effect (i.e., in milliseconds or percentages) are sometimes more <em>scientifically</em> meaningful. But we’ll follow their choice now.</p>
<p>We’ll also need a likelihood function. The likelihood is going to describe the likely values of <span class="math inline">\(\delta\)</span> given our data. So the most likely value will be our observed effect size, and values <span class="math inline">\(\delta\)</span> will be less likely as we move away from this value. Unlike our coin flipping case it’s pretty hard to do a simulation to derive the likelihood ourselves. But if we did, we’d see that it follows a <em>t</em> likelihood with <em>N - 1</em> degrees of freedom. This is what Rouder et al use.</p>
<p>Next, we’ll need a model of our <em>model 1</em> or <em>null hypothesis</em> (ie., <span class="math inline">\(\mathcal{H}_0\)</span>). Following Rouder, we’ll pick the hypothesis that <span class="math inline">\(\delta\)</span> = 0 as our <span class="math inline">\(\mathcal{H}_0\)</span>. Up until now, we’ve only picked a single point for our model 1, but we don’t need to. To define our model 1, we’ll just say that for all values of <span class="math inline">\(\delta \neq\)</span> 0 will be weighted 0, and <span class="math inline">\(\delta\)</span> = 0 will be weighted 1.</p>
<p>Finally, we need a model for our <em>model 2</em> or <em>alternative hypothesis</em> (i.e., <span class="math inline">\(\mathcal{H}_1\)</span>). Here Rouder et al (2009) aim for a non-informative prior<sup>1</sup>. Their choice, it turns out, it a <strong>Cauchy</strong> distribution. They derive this from some mathematical considerations. This means that this prior is not characterising their beliefs about <strong>reasonable</strong> effect sizes. In fact, we’ll see that it puts <strong>a lot</strong> of weight on completely unreasonable values that no scientific theory would predict. But that isn’t there aim. They’re trying to commit to as little as possible with their prior.</p>
<p>Now that we have all the bits we need, we can start building up our Bayes factor.</p>
<p><sup>1</sup><small>Their exact model is slightly different, involving a prior on effect size and on the standard deviation, but we can ignore this complication for now.</small></p>
<p>The first step is our effect size parameter. This is calculated as the sample mean scaled by the sample standard deviation. That is:
<span class="math display">\[\delta=\frac{\mathrm{mean}}{\mathrm{sd}}\]</span></p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="computing-bayes-factors-part-i.html#cb66-1"></a><span class="co"># 5</span></span>
<span id="cb66-2"><a href="computing-bayes-factors-part-i.html#cb66-2"></a><span class="co"># calculate delta </span></span>
<span id="cb66-3"><a href="computing-bayes-factors-part-i.html#cb66-3"></a></span>
<span id="cb66-4"><a href="computing-bayes-factors-part-i.html#cb66-4"></a>delta =<span class="st"> </span><span class="kw">mean</span>(g_m_<span class="dv">2008</span>_data) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(g_m_<span class="dv">2008</span>_data)</span>
<span id="cb66-5"><a href="computing-bayes-factors-part-i.html#cb66-5"></a></span>
<span id="cb66-6"><a href="computing-bayes-factors-part-i.html#cb66-6"></a>glue<span class="op">::</span><span class="kw">glue</span>(<span class="st">&quot;The observed effect size is {round(delta,2)}&quot;</span>) </span></code></pre></div>
<p>The observed effect size is 0.25</p>
<p>The next step is our likelihood function. We’ll define it with <code>t.lik</code> function from the <strong>bayesplay</strong> package. It’ll be centred at our <span class="math inline">\(\delta\)</span> valued and will have N - 1 degrees of freedom. It is used as follows:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="computing-bayes-factors-part-i.html#cb67-1"></a>data_model =<span class="st"> </span><span class="kw">t.lik</span>(<span class="dt">center =</span> ... , <span class="dt">df =</span> ...)</span></code></pre></div>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="computing-bayes-factors-part-i.html#cb68-1"></a><span class="co"># 6 </span></span>
<span id="cb68-2"><a href="computing-bayes-factors-part-i.html#cb68-2"></a></span>
<span id="cb68-3"><a href="computing-bayes-factors-part-i.html#cb68-3"></a><span class="co"># Lets set up our likelihood</span></span>
<span id="cb68-4"><a href="computing-bayes-factors-part-i.html#cb68-4"></a><span class="co"># we&#39;ve already calculated the delta which will be the centre</span></span>
<span id="cb68-5"><a href="computing-bayes-factors-part-i.html#cb68-5"></a><span class="co"># so we only need the number of data point</span></span>
<span id="cb68-6"><a href="computing-bayes-factors-part-i.html#cb68-6"></a></span>
<span id="cb68-7"><a href="computing-bayes-factors-part-i.html#cb68-7"></a><span class="co"># calculate df</span></span>
<span id="cb68-8"><a href="computing-bayes-factors-part-i.html#cb68-8"></a>df =<span class="st"> </span><span class="kw">length</span>(g_m_<span class="dv">2008</span>_data) <span class="op">-</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb68-9"><a href="computing-bayes-factors-part-i.html#cb68-9"></a></span>
<span id="cb68-10"><a href="computing-bayes-factors-part-i.html#cb68-10"></a><span class="co"># define liklihood </span></span>
<span id="cb68-11"><a href="computing-bayes-factors-part-i.html#cb68-11"></a></span>
<span id="cb68-12"><a href="computing-bayes-factors-part-i.html#cb68-12"></a>data_model =<span class="st"> </span><span class="kw">t.lik</span>(<span class="dt">center =</span> delta, <span class="dt">df =</span> df)</span>
<span id="cb68-13"><a href="computing-bayes-factors-part-i.html#cb68-13"></a>data_model</span></code></pre></div>
<p>Object of class likelihood
Likelihood type: non-central t
Parameters
Center: 0.250439613479976
DF: 79</p>
<p>To help us get a better idea of the likelihood, we’ll plot it. We’ll also mark our observation, which should be the most likely parameter value. To plot the likelihood we just use the <code>plot()</code> function. As inputs, it takes the <code>likelihood</code> object and the range of <span class="math inline">\(\delta\)</span> values you want to plot over. E.g.:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="computing-bayes-factors-part-i.html#cb69-1"></a><span class="kw">plot</span>(data_model, <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-1</span>, <span class="dt">to =</span> <span class="dv">1</span>,<span class="dt">by =</span> <span class="fl">0.001</span>))</span></code></pre></div>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="computing-bayes-factors-part-i.html#cb70-1"></a><span class="co"># 7</span></span>
<span id="cb70-2"><a href="computing-bayes-factors-part-i.html#cb70-2"></a></span>
<span id="cb70-3"><a href="computing-bayes-factors-part-i.html#cb70-3"></a><span class="co"># Let&#39;s plot the likelihood function</span></span>
<span id="cb70-4"><a href="computing-bayes-factors-part-i.html#cb70-4"></a><span class="co"># We&#39;ll make the plot and then style it with standard ggplot syntax</span></span>
<span id="cb70-5"><a href="computing-bayes-factors-part-i.html#cb70-5"></a></span>
<span id="cb70-6"><a href="computing-bayes-factors-part-i.html#cb70-6"></a><span class="kw">plot</span>(data_model, <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-1</span>, <span class="dt">to =</span> <span class="dv">1</span>,<span class="dt">by =</span> <span class="fl">0.001</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb70-7"><a href="computing-bayes-factors-part-i.html#cb70-7"></a><span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;δ&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb70-8"><a href="computing-bayes-factors-part-i.html#cb70-8"></a><span class="st">    </span><span class="kw">theme_minimal</span>(<span class="dv">12</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb70-9"><a href="computing-bayes-factors-part-i.html#cb70-9"></a><span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> delta, <span class="dt">linetype =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="book_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<p>Now that we have our likelihood’s we’ll need to define our two models. The syntax for defining models is a little clunky, but essentially we just need to give a weighting for every possible value of <span class="math inline">\(\delta\)</span>. These should also (ideally) be proper probability distributions.</p>
<p>Most of our priors are either going to be <strong>normal distributions</strong>, <strong>cauchy distributions</strong>, <strong>uniform distributions</strong>, <strong>t distributions</strong> or similar. Luckily <strong>R</strong> provides functions for these probability densities. They’re are <code>dnorm()</code>, <code>dcauchy()</code>, <code>dunif()</code>, and <code>dt()</code> respectively. The basic structure of specifying a prior is as follows:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="computing-bayes-factors-part-i.html#cb71-1"></a>prior =<span class="st"> </span><span class="cf">function</span>(theta.range)</span>
<span id="cb71-2"><a href="computing-bayes-factors-part-i.html#cb71-2"></a>    {</span>
<span id="cb71-3"><a href="computing-bayes-factors-part-i.html#cb71-3"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) PRIOR_FUNCTION,</span>
<span id="cb71-4"><a href="computing-bayes-factors-part-i.html#cb71-4"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb71-5"><a href="computing-bayes-factors-part-i.html#cb71-5"></a>    }</span></code></pre></div>
<p>For our <span class="math inline">\(\mathcal{H}_0\)</span>, we’ll use a <strong>point null</strong> (just as we’ve been using for our coin flips). Our point null just says <span class="math inline">\(\delta\)</span> = 0.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="computing-bayes-factors-part-i.html#cb72-1"></a><span class="co"># 8</span></span>
<span id="cb72-2"><a href="computing-bayes-factors-part-i.html#cb72-2"></a></span>
<span id="cb72-3"><a href="computing-bayes-factors-part-i.html#cb72-3"></a><span class="co"># we&#39;ll start by defining the null prior. </span></span>
<span id="cb72-4"><a href="computing-bayes-factors-part-i.html#cb72-4"></a><span class="co"># this is, for all values other than delta = 0, set the weight to 0, and when </span></span>
<span id="cb72-5"><a href="computing-bayes-factors-part-i.html#cb72-5"></a><span class="co"># delta = 0, set the weight to 1</span></span>
<span id="cb72-6"><a href="computing-bayes-factors-part-i.html#cb72-6"></a></span>
<span id="cb72-7"><a href="computing-bayes-factors-part-i.html#cb72-7"></a>h0_model =<span class="st"> </span><span class="cf">function</span>(theta.range){</span>
<span id="cb72-8"><a href="computing-bayes-factors-part-i.html#cb72-8"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) <span class="kw">ifelse</span>(theta <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb72-9"><a href="computing-bayes-factors-part-i.html#cb72-9"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb72-10"><a href="computing-bayes-factors-part-i.html#cb72-10"></a>}</span></code></pre></div>
<p>Now that we’ve defined our <span class="math inline">\(\mathcal{H}_0\)</span>, we’ll define <span class="math inline">\(\mathcal{H}_1\)</span>. Following Rouder et al we’ll use a <strong>cauchy</strong> distribution. It’s defined as follows:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="computing-bayes-factors-part-i.html#cb73-1"></a><span class="co"># 9 </span></span>
<span id="cb73-2"><a href="computing-bayes-factors-part-i.html#cb73-2"></a></span>
<span id="cb73-3"><a href="computing-bayes-factors-part-i.html#cb73-3"></a><span class="co"># now we define the &quot;alternative&quot; prior</span></span>
<span id="cb73-4"><a href="computing-bayes-factors-part-i.html#cb73-4"></a><span class="co"># this will be a standard cauchy distribution</span></span>
<span id="cb73-5"><a href="computing-bayes-factors-part-i.html#cb73-5"></a></span>
<span id="cb73-6"><a href="computing-bayes-factors-part-i.html#cb73-6"></a>h1_model =<span class="st"> </span><span class="cf">function</span>(theta.range){</span>
<span id="cb73-7"><a href="computing-bayes-factors-part-i.html#cb73-7"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) <span class="kw">dcauchy</span>(<span class="dt">x =</span> theta, <span class="dt">location =</span> <span class="dv">0</span>, <span class="dt">scale =</span> <span class="dv">1</span>),</span>
<span id="cb73-8"><a href="computing-bayes-factors-part-i.html#cb73-8"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb73-9"><a href="computing-bayes-factors-part-i.html#cb73-9"></a>}</span></code></pre></div>
<p>We’ll also plot our prior, so we can get an idea of what it looks like.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="computing-bayes-factors-part-i.html#cb74-1"></a><span class="co"># 10</span></span>
<span id="cb74-2"><a href="computing-bayes-factors-part-i.html#cb74-2"></a></span>
<span id="cb74-3"><a href="computing-bayes-factors-part-i.html#cb74-3"></a><span class="co"># plot the prior</span></span>
<span id="cb74-4"><a href="computing-bayes-factors-part-i.html#cb74-4"></a></span>
<span id="cb74-5"><a href="computing-bayes-factors-part-i.html#cb74-5"></a><span class="co"># first set the range of values for the plot</span></span>
<span id="cb74-6"><a href="computing-bayes-factors-part-i.html#cb74-6"></a></span>
<span id="cb74-7"><a href="computing-bayes-factors-part-i.html#cb74-7"></a>theta.range =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>,.<span class="dv">1</span>) <span class="co"># from -10 to +10 in steps 0.1</span></span>
<span id="cb74-8"><a href="computing-bayes-factors-part-i.html#cb74-8"></a></span>
<span id="cb74-9"><a href="computing-bayes-factors-part-i.html#cb74-9"></a><span class="co"># then make a tibble with the data for the plot</span></span>
<span id="cb74-10"><a href="computing-bayes-factors-part-i.html#cb74-10"></a><span class="kw">tibble</span>(<span class="dt">theta =</span> theta.range, <span class="dt">p =</span> <span class="kw">h1_model</span>(theta.range)<span class="op">$</span><span class="kw">func</span>(theta.range)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb74-11"><a href="computing-bayes-factors-part-i.html#cb74-11"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">y =</span> p)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span><span class="kw">scale_x_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;δ&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb74-12"><a href="computing-bayes-factors-part-i.html#cb74-12"></a><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;p(δ)&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>(<span class="dv">12</span>)</span></code></pre></div>
<p><img src="book_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<p>As you can see there’s still a fair bit of weight at values of <span class="math inline">\(\delta\pm\)</span> 5. These are unreasonable values for an effect size, but this prior isn’t about Rouder et al’s beliefs about reasonable effect sizes, so it’s not a concern to them.</p>
<p>Now that we have all the bits we need, we can work out the <strong>Bayes factor</strong>. We’ll jump back to our formula:</p>
<p><span class="math display">\[\mathcal{M}_H = \int_{\theta\in\Theta_H}\mathcal{L}_H(\theta|\mathbf{y})p(\theta)d\theta\]</span></p>
<p>This tells us that to work our the value for <span class="math inline">\(\mathcal{M}_H\)</span> we need to take the likelihood, multiply it by the prior, and then take the integral. And all this needs to be done over the <em>range</em> that the parameter takes. Effect sizes span the entire range of real numbers (i.e., <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(+\infty\)</span>) so that’ll be our range for the alternative. For the null model, we’re only interested in one value of <span class="math inline">\(\delta\)</span> — when <span class="math inline">\(\delta\)</span> = 0. So we’ll use the range (0,0) instead.</p>
<p>To do this, we just use the following syntax:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="computing-bayes-factors-part-i.html#cb75-1"></a>H_M =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">hm_model</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(minval,maxval))</span></code></pre></div>
<p>Let’s perform the calculation for <span class="math inline">\(\mathcal{H}_0\)</span>:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="computing-bayes-factors-part-i.html#cb76-1"></a><span class="co"># 11</span></span>
<span id="cb76-2"><a href="computing-bayes-factors-part-i.html#cb76-2"></a></span>
<span id="cb76-3"><a href="computing-bayes-factors-part-i.html#cb76-3"></a><span class="co"># multiple the prior and likelihood for H_0</span></span>
<span id="cb76-4"><a href="computing-bayes-factors-part-i.html#cb76-4"></a></span>
<span id="cb76-5"><a href="computing-bayes-factors-part-i.html#cb76-5"></a>M0 =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">h0_model</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb76-6"><a href="computing-bayes-factors-part-i.html#cb76-6"></a>M0</span></code></pre></div>
<p>Object of class marginal
Parameter range: from 0 to 0
Area under the curve (integral): 0.03386948
Prior function: function(theta) ifelse(theta == 0, 1, 0)
Likelihood function:</p>
<p>And then we’l do the same for <span class="math inline">\(\mathcal{H}_1\)</span>:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="computing-bayes-factors-part-i.html#cb77-1"></a><span class="co"># 12</span></span>
<span id="cb77-2"><a href="computing-bayes-factors-part-i.html#cb77-2"></a></span>
<span id="cb77-3"><a href="computing-bayes-factors-part-i.html#cb77-3"></a><span class="co"># multiple the prior and likelihood for H_1</span></span>
<span id="cb77-4"><a href="computing-bayes-factors-part-i.html#cb77-4"></a></span>
<span id="cb77-5"><a href="computing-bayes-factors-part-i.html#cb77-5"></a>M1 =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">h1_model</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(<span class="op">-</span><span class="ot">Inf</span>, <span class="ot">Inf</span>))</span>
<span id="cb77-6"><a href="computing-bayes-factors-part-i.html#cb77-6"></a>M1</span></code></pre></div>
<p>Object of class marginal
Parameter range: from -Inf to Inf
Area under the curve (integral): 0.033066
Prior function: function(theta) dcauchy(x = theta, location = 0, scale = 1)
Likelihood function:</p>
<p>Finally to work out the <strong>Bayes factor</strong> we just need to take the integral of model 1 and model 2, and then take the ratio of those values.</p>
<p>To get the integral of a model just use the following syntax:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="computing-bayes-factors-part-i.html#cb78-1"></a>M_H<span class="op">$</span>integral</span></code></pre></div>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="computing-bayes-factors-part-i.html#cb79-1"></a><span class="co"># 13</span></span>
<span id="cb79-2"><a href="computing-bayes-factors-part-i.html#cb79-2"></a></span>
<span id="cb79-3"><a href="computing-bayes-factors-part-i.html#cb79-3"></a>BF01 =<span class="st"> </span>M0<span class="op">$</span>integral <span class="op">/</span><span class="st"> </span>M1<span class="op">$</span>integral</span>
<span id="cb79-4"><a href="computing-bayes-factors-part-i.html#cb79-4"></a>BF01</span></code></pre></div>
<p>[1] 1.024299</p>
<p>Now let’s compare our home made <strong>BF</strong> to the store bought version.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="computing-bayes-factors-part-i.html#cb80-1"></a><span class="co"># 14</span></span>
<span id="cb80-2"><a href="computing-bayes-factors-part-i.html#cb80-2"></a></span>
<span id="cb80-3"><a href="computing-bayes-factors-part-i.html#cb80-3"></a>glue<span class="op">::</span><span class="kw">glue</span>(<span class="st">&quot;The store bought **BF** using the **Bayes factor** package is {round(tidy(store_bought_bf)$BF01,2)}   </span></span>
<span id="cb80-4"><a href="computing-bayes-factors-part-i.html#cb80-4"></a><span class="st">The one we made at home is {round(BF01,2)}&quot;</span>)</span></code></pre></div>
<p>The store bought <strong>BF</strong> using the <strong>Bayes factor</strong> package is 1.02<br />
The one we made at home is 1.02</p>
<p>We can put everything together in a single code block so it’s easier to follow:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="computing-bayes-factors-part-i.html#cb81-1"></a><span class="co"># 15</span></span>
<span id="cb81-2"><a href="computing-bayes-factors-part-i.html#cb81-2"></a></span>
<span id="cb81-3"><a href="computing-bayes-factors-part-i.html#cb81-3"></a><span class="co"># calculate observed parameter value</span></span>
<span id="cb81-4"><a href="computing-bayes-factors-part-i.html#cb81-4"></a>delta =<span class="st"> </span><span class="kw">mean</span>(g_m_<span class="dv">2008</span>_data) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(g_m_<span class="dv">2008</span>_data)</span>
<span id="cb81-5"><a href="computing-bayes-factors-part-i.html#cb81-5"></a></span>
<span id="cb81-6"><a href="computing-bayes-factors-part-i.html#cb81-6"></a><span class="co"># define liklihood </span></span>
<span id="cb81-7"><a href="computing-bayes-factors-part-i.html#cb81-7"></a>data_model =<span class="st"> </span><span class="kw">t.lik</span>(<span class="dt">center =</span> delta, <span class="dt">df =</span> <span class="kw">length</span>(g_m_<span class="dv">2008</span>_data) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb81-8"><a href="computing-bayes-factors-part-i.html#cb81-8"></a></span>
<span id="cb81-9"><a href="computing-bayes-factors-part-i.html#cb81-9"></a><span class="co"># define model / priors</span></span>
<span id="cb81-10"><a href="computing-bayes-factors-part-i.html#cb81-10"></a></span>
<span id="cb81-11"><a href="computing-bayes-factors-part-i.html#cb81-11"></a>h0_model =<span class="st"> </span><span class="cf">function</span>(theta.range){</span>
<span id="cb81-12"><a href="computing-bayes-factors-part-i.html#cb81-12"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) <span class="kw">ifelse</span>(theta <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb81-13"><a href="computing-bayes-factors-part-i.html#cb81-13"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb81-14"><a href="computing-bayes-factors-part-i.html#cb81-14"></a>}</span>
<span id="cb81-15"><a href="computing-bayes-factors-part-i.html#cb81-15"></a></span>
<span id="cb81-16"><a href="computing-bayes-factors-part-i.html#cb81-16"></a></span>
<span id="cb81-17"><a href="computing-bayes-factors-part-i.html#cb81-17"></a>h1_model =<span class="st"> </span><span class="cf">function</span>(theta.range){</span>
<span id="cb81-18"><a href="computing-bayes-factors-part-i.html#cb81-18"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) <span class="kw">dcauchy</span>(<span class="dt">x =</span> theta, <span class="dt">location =</span> <span class="dv">0</span>, <span class="dt">scale =</span> <span class="dv">1</span>),</span>
<span id="cb81-19"><a href="computing-bayes-factors-part-i.html#cb81-19"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb81-20"><a href="computing-bayes-factors-part-i.html#cb81-20"></a>}</span>
<span id="cb81-21"><a href="computing-bayes-factors-part-i.html#cb81-21"></a></span>
<span id="cb81-22"><a href="computing-bayes-factors-part-i.html#cb81-22"></a><span class="co"># multiply the prior and likelihoods and priors</span></span>
<span id="cb81-23"><a href="computing-bayes-factors-part-i.html#cb81-23"></a></span>
<span id="cb81-24"><a href="computing-bayes-factors-part-i.html#cb81-24"></a>M0 =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">h0_model</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb81-25"><a href="computing-bayes-factors-part-i.html#cb81-25"></a></span>
<span id="cb81-26"><a href="computing-bayes-factors-part-i.html#cb81-26"></a>M1 =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">h1_model</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(<span class="op">-</span><span class="ot">Inf</span>, <span class="ot">Inf</span>))</span>
<span id="cb81-27"><a href="computing-bayes-factors-part-i.html#cb81-27"></a></span>
<span id="cb81-28"><a href="computing-bayes-factors-part-i.html#cb81-28"></a><span class="co"># take the intergral and divide</span></span>
<span id="cb81-29"><a href="computing-bayes-factors-part-i.html#cb81-29"></a></span>
<span id="cb81-30"><a href="computing-bayes-factors-part-i.html#cb81-30"></a>BF01 =<span class="st"> </span>M0<span class="op">$</span>integral <span class="op">/</span><span class="st"> </span>M1<span class="op">$</span>integral</span>
<span id="cb81-31"><a href="computing-bayes-factors-part-i.html#cb81-31"></a>glue<span class="op">::</span><span class="kw">glue</span>(<span class="st">&quot;B&lt;sub&gt;01&lt;/sub&gt; = {round(BF01,2)}  </span></span>
<span id="cb81-32"><a href="computing-bayes-factors-part-i.html#cb81-32"></a><span class="st">B&lt;sub&gt;10&lt;/sub&gt; = {round(1/BF01,2)}&quot;</span>)</span></code></pre></div>
<p>B<sub>01</sub> = 1.02<br />
B<sub>10</sub> = 0.98</p>
<p>We can also work through the second example provided in Rouder et al (2009). Again, this deals with data from Grider and Malmberg (2008). This time, however, we’ll work directly from the summary stats as an example.</p>
<p>Rouder et al (2009) give the two condition means as 0.76 and 0.79, and they report the <em>t</em> statistic as 2.03. For the <strong>Bayes factor</strong>, they give a BF of <span class="math inline">\(\frac{\mathcal{H}_0}{\mathcal{H}_1}\)</span> of 1.56.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="computing-bayes-factors-part-i.html#cb82-1"></a><span class="co"># 16</span></span>
<span id="cb82-2"><a href="computing-bayes-factors-part-i.html#cb82-2"></a><span class="co"># calculate observed parameter value</span></span>
<span id="cb82-3"><a href="computing-bayes-factors-part-i.html#cb82-3"></a><span class="co"># effect sizes are just t / sqrt(N)</span></span>
<span id="cb82-4"><a href="computing-bayes-factors-part-i.html#cb82-4"></a>t_value =<span class="st"> </span><span class="fl">2.03</span></span>
<span id="cb82-5"><a href="computing-bayes-factors-part-i.html#cb82-5"></a>N =<span class="st"> </span><span class="dv">80</span></span>
<span id="cb82-6"><a href="computing-bayes-factors-part-i.html#cb82-6"></a>delta =<span class="st"> </span>t_value <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(N)</span>
<span id="cb82-7"><a href="computing-bayes-factors-part-i.html#cb82-7"></a></span>
<span id="cb82-8"><a href="computing-bayes-factors-part-i.html#cb82-8"></a><span class="co"># define liklihood </span></span>
<span id="cb82-9"><a href="computing-bayes-factors-part-i.html#cb82-9"></a>data_model =<span class="st"> </span><span class="kw">t.lik</span>(<span class="dt">center =</span> delta, <span class="dt">df =</span> N <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb82-10"><a href="computing-bayes-factors-part-i.html#cb82-10"></a></span>
<span id="cb82-11"><a href="computing-bayes-factors-part-i.html#cb82-11"></a><span class="co"># define model / priors</span></span>
<span id="cb82-12"><a href="computing-bayes-factors-part-i.html#cb82-12"></a></span>
<span id="cb82-13"><a href="computing-bayes-factors-part-i.html#cb82-13"></a>h0_model =<span class="st"> </span><span class="cf">function</span>(theta.range){</span>
<span id="cb82-14"><a href="computing-bayes-factors-part-i.html#cb82-14"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) <span class="kw">ifelse</span>(theta <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb82-15"><a href="computing-bayes-factors-part-i.html#cb82-15"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb82-16"><a href="computing-bayes-factors-part-i.html#cb82-16"></a>}</span>
<span id="cb82-17"><a href="computing-bayes-factors-part-i.html#cb82-17"></a></span>
<span id="cb82-18"><a href="computing-bayes-factors-part-i.html#cb82-18"></a></span>
<span id="cb82-19"><a href="computing-bayes-factors-part-i.html#cb82-19"></a>h1_model =<span class="st"> </span><span class="cf">function</span>(theta.range){</span>
<span id="cb82-20"><a href="computing-bayes-factors-part-i.html#cb82-20"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) <span class="kw">dcauchy</span>(<span class="dt">x =</span> theta, <span class="dt">location =</span> <span class="dv">0</span>, <span class="dt">scale =</span> <span class="dv">1</span>),</span>
<span id="cb82-21"><a href="computing-bayes-factors-part-i.html#cb82-21"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb82-22"><a href="computing-bayes-factors-part-i.html#cb82-22"></a>}</span>
<span id="cb82-23"><a href="computing-bayes-factors-part-i.html#cb82-23"></a></span>
<span id="cb82-24"><a href="computing-bayes-factors-part-i.html#cb82-24"></a><span class="co"># multiply the prior and likelihoods</span></span>
<span id="cb82-25"><a href="computing-bayes-factors-part-i.html#cb82-25"></a></span>
<span id="cb82-26"><a href="computing-bayes-factors-part-i.html#cb82-26"></a>M0 =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">h0_model</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb82-27"><a href="computing-bayes-factors-part-i.html#cb82-27"></a></span>
<span id="cb82-28"><a href="computing-bayes-factors-part-i.html#cb82-28"></a>M1 =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">h1_model</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(<span class="op">-</span><span class="ot">Inf</span>, <span class="ot">Inf</span>))</span>
<span id="cb82-29"><a href="computing-bayes-factors-part-i.html#cb82-29"></a></span>
<span id="cb82-30"><a href="computing-bayes-factors-part-i.html#cb82-30"></a><span class="co"># take the intergral and divide</span></span>
<span id="cb82-31"><a href="computing-bayes-factors-part-i.html#cb82-31"></a></span>
<span id="cb82-32"><a href="computing-bayes-factors-part-i.html#cb82-32"></a>BF01 =<span class="st">  </span>M0<span class="op">$</span>integral <span class="op">/</span><span class="st"> </span>M1<span class="op">$</span>integral</span>
<span id="cb82-33"><a href="computing-bayes-factors-part-i.html#cb82-33"></a>glue<span class="op">::</span><span class="kw">glue</span>(<span class="st">&quot;B&lt;sub&gt;01&lt;/sub&gt; = {round(BF01,2)}  </span></span>
<span id="cb82-34"><a href="computing-bayes-factors-part-i.html#cb82-34"></a><span class="st">B&lt;sub&gt;10&lt;/sub&gt; = {round(1/BF01,2)}&quot;</span>) </span></code></pre></div>
<p>B<sub>01</sub> = 1.56<br />
B<sub>10</sub> = 0.64</p>
<p>Now that we’re making our own <strong>Bayes factors</strong> we don’t have to use the built in priors. We can make our own if we want to. Do you think Rouder et al’s choices are reasonable? Do you have any other suggestions?</p>
<p>One possibility for an alternative prior is actually suggested by Rouder et al. They refer to it as the <strong>unit information prior</strong>. The unit information prior is just a standard normal distribution—that is, a normal distribution with a mean of 0 and a standard deviation of 1.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="computing-bayes-factors-part-i.html#cb83-1"></a><span class="co"># 17</span></span>
<span id="cb83-2"><a href="computing-bayes-factors-part-i.html#cb83-2"></a></span>
<span id="cb83-3"><a href="computing-bayes-factors-part-i.html#cb83-3"></a><span class="co"># define the prior</span></span>
<span id="cb83-4"><a href="computing-bayes-factors-part-i.html#cb83-4"></a></span>
<span id="cb83-5"><a href="computing-bayes-factors-part-i.html#cb83-5"></a>h1_unit_information =<span class="st"> </span><span class="cf">function</span>(theta.range){</span>
<span id="cb83-6"><a href="computing-bayes-factors-part-i.html#cb83-6"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) <span class="kw">dnorm</span>(<span class="dt">x =</span> theta, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>),</span>
<span id="cb83-7"><a href="computing-bayes-factors-part-i.html#cb83-7"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb83-8"><a href="computing-bayes-factors-part-i.html#cb83-8"></a>}</span>
<span id="cb83-9"><a href="computing-bayes-factors-part-i.html#cb83-9"></a></span>
<span id="cb83-10"><a href="computing-bayes-factors-part-i.html#cb83-10"></a></span>
<span id="cb83-11"><a href="computing-bayes-factors-part-i.html#cb83-11"></a></span>
<span id="cb83-12"><a href="computing-bayes-factors-part-i.html#cb83-12"></a><span class="co"># plot it over a reasonable range of theta</span></span>
<span id="cb83-13"><a href="computing-bayes-factors-part-i.html#cb83-13"></a>theta.range =<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>,.<span class="dv">01</span>) </span>
<span id="cb83-14"><a href="computing-bayes-factors-part-i.html#cb83-14"></a></span>
<span id="cb83-15"><a href="computing-bayes-factors-part-i.html#cb83-15"></a><span class="co"># then make a tibble with the data for the plot</span></span>
<span id="cb83-16"><a href="computing-bayes-factors-part-i.html#cb83-16"></a><span class="kw">tibble</span>(<span class="dt">theta =</span> theta.range, <span class="dt">p =</span> <span class="kw">h1_unit_information</span>(theta.range)<span class="op">$</span><span class="kw">func</span>(theta.range)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb83-17"><a href="computing-bayes-factors-part-i.html#cb83-17"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">y =</span> p)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span><span class="kw">scale_x_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;δ&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb83-18"><a href="computing-bayes-factors-part-i.html#cb83-18"></a><span class="kw">scale_y_continuous</span>(<span class="dt">name =</span> <span class="st">&quot;p(δ)&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>(<span class="dv">12</span>)</span></code></pre></div>
<p><img src="book_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
<p>If you compare the plot above to the Cauchy prior you’ll notice that the drop off is a lot steeper. This choice of prior seems to do a better job of actually reflecting our beliefs about the reasonable range of effect sizes in <strong>psychology in general</strong>. There’s no appreciable mass at anything beyond 2.5, unlike the Cauchy which still had a lot of weight beyond 5.</p>
<p>Let’s compute a <strong>Bayes factor</strong> using this new model. We don’t have to re-specify the likelihood or the null model, because we’ll just re-use everything from the previous example.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="computing-bayes-factors-part-i.html#cb84-1"></a><span class="co"># 18</span></span>
<span id="cb84-2"><a href="computing-bayes-factors-part-i.html#cb84-2"></a></span>
<span id="cb84-3"><a href="computing-bayes-factors-part-i.html#cb84-3"></a>M1_unit_info =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">h1_unit_information</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(<span class="op">-</span><span class="ot">Inf</span>, <span class="ot">Inf</span>))</span>
<span id="cb84-4"><a href="computing-bayes-factors-part-i.html#cb84-4"></a></span>
<span id="cb84-5"><a href="computing-bayes-factors-part-i.html#cb84-5"></a>BF01 =<span class="st">  </span>M0<span class="op">$</span>integral <span class="op">/</span><span class="st"> </span>M1_unit_info<span class="op">$</span>integral</span>
<span id="cb84-6"><a href="computing-bayes-factors-part-i.html#cb84-6"></a>glue<span class="op">::</span><span class="kw">glue</span>(<span class="st">&quot;B&lt;sub&gt;01&lt;/sub&gt; = {round(BF01,2)}  </span></span>
<span id="cb84-7"><a href="computing-bayes-factors-part-i.html#cb84-7"></a><span class="st">B&lt;sub&gt;10&lt;/sub&gt; = {round(1/BF01,2)}&quot;</span>) </span></code></pre></div>
<p>B<sub>01</sub> = 1.21<br />
B<sub>10</sub> = 0.83</p>
<p>We can see that the two priors yielded numerically different results. But they’re not so different as to warrant different conclusions. We can try a range of <strong>reasonable</strong> priors to see how our conclusions change.</p>
<p>But we can also try completely <strong>unreasonable</strong> priors. For example, Let’s say that our alternative model consists of only a single value—the observed value.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="computing-bayes-factors-part-i.html#cb85-1"></a><span class="co"># 19</span></span>
<span id="cb85-2"><a href="computing-bayes-factors-part-i.html#cb85-2"></a></span>
<span id="cb85-3"><a href="computing-bayes-factors-part-i.html#cb85-3"></a>h1_psychic =<span class="st"> </span><span class="cf">function</span>(theta.range){</span>
<span id="cb85-4"><a href="computing-bayes-factors-part-i.html#cb85-4"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) <span class="kw">ifelse</span>(theta <span class="op">==</span><span class="st"> </span>delta, <span class="dv">1</span>, <span class="dv">0</span>) ,</span>
<span id="cb85-5"><a href="computing-bayes-factors-part-i.html#cb85-5"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb85-6"><a href="computing-bayes-factors-part-i.html#cb85-6"></a>}</span>
<span id="cb85-7"><a href="computing-bayes-factors-part-i.html#cb85-7"></a></span>
<span id="cb85-8"><a href="computing-bayes-factors-part-i.html#cb85-8"></a>M1_psychic =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">h1_psychic</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(delta, delta))</span>
<span id="cb85-9"><a href="computing-bayes-factors-part-i.html#cb85-9"></a></span>
<span id="cb85-10"><a href="computing-bayes-factors-part-i.html#cb85-10"></a>BF01 =<span class="st">  </span>M0<span class="op">$</span>integral <span class="op">/</span><span class="st"> </span>M1_psychic<span class="op">$</span>integral</span>
<span id="cb85-11"><a href="computing-bayes-factors-part-i.html#cb85-11"></a>glue<span class="op">::</span><span class="kw">glue</span>(<span class="st">&quot;B&lt;sub&gt;01&lt;/sub&gt; = {round(BF01,2)}  </span></span>
<span id="cb85-12"><a href="computing-bayes-factors-part-i.html#cb85-12"></a><span class="st">B&lt;sub&gt;10&lt;/sub&gt; = {round(1/BF01,2)}&quot;</span>) </span></code></pre></div>
<p>B<sub>01</sub> = 0.13<br />
B<sub>10</sub> = 7.55</p>
<p>Or alternatively, we might set our alternative to equally weight all values of <span class="math inline">\(\delta\)</span> from -100 to +100. Again, this is completely unreasonable and it’s just done as an illustration.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="computing-bayes-factors-part-i.html#cb86-1"></a><span class="co"># 20 </span></span>
<span id="cb86-2"><a href="computing-bayes-factors-part-i.html#cb86-2"></a></span>
<span id="cb86-3"><a href="computing-bayes-factors-part-i.html#cb86-3"></a>h1_uniform =<span class="st"> </span><span class="cf">function</span>(theta.range){</span>
<span id="cb86-4"><a href="computing-bayes-factors-part-i.html#cb86-4"></a>    <span class="kw">list</span>(<span class="dt">func =</span> <span class="cf">function</span>(theta) <span class="kw">dunif</span>(<span class="dt">x =</span> theta, <span class="dt">min =</span> <span class="dv">-100</span>, <span class="dt">max =</span> <span class="dv">100</span>) ,</span>
<span id="cb86-5"><a href="computing-bayes-factors-part-i.html#cb86-5"></a>         <span class="dt">theta.range =</span> theta.range)</span>
<span id="cb86-6"><a href="computing-bayes-factors-part-i.html#cb86-6"></a>}</span>
<span id="cb86-7"><a href="computing-bayes-factors-part-i.html#cb86-7"></a></span>
<span id="cb86-8"><a href="computing-bayes-factors-part-i.html#cb86-8"></a>M1_uniform =<span class="st"> </span>data_model <span class="op">*</span><span class="st"> </span><span class="kw">h1_uniform</span>(<span class="dt">theta.range =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">100</span>, <span class="dv">100</span>))</span>
<span id="cb86-9"><a href="computing-bayes-factors-part-i.html#cb86-9"></a></span>
<span id="cb86-10"><a href="computing-bayes-factors-part-i.html#cb86-10"></a>BF01 =<span class="st">  </span>M0<span class="op">$</span>integral <span class="op">/</span><span class="st"> </span>M1_uniform<span class="op">$</span>integral</span>
<span id="cb86-11"><a href="computing-bayes-factors-part-i.html#cb86-11"></a>glue<span class="op">::</span><span class="kw">glue</span>(<span class="st">&quot;B&lt;sub&gt;01&lt;/sub&gt; = {round(BF01,2)}  </span></span>
<span id="cb86-12"><a href="computing-bayes-factors-part-i.html#cb86-12"></a><span class="st">B&lt;sub&gt;10&lt;/sub&gt; = {round(1/BF01,2)}&quot;</span>) </span></code></pre></div>
<p>B<sub>01</sub> = 97.42<br />
B<sub>10</sub> = 0.01</p>
<p>Rouder et al’s approach is to place priors on <strong>effect size</strong>. Effect sizes might be an attractive choice of parametrisation when we’re trying to come up with priors that are <em>widely applicable</em>. But when we’re thinking of <em>scientific theories</em> or <em>reasoning about effects</em>, it’s often easier to do it in terms of <strong>raw effects</strong>—that is, what is the difference in <em>milliseconds</em> or in <em>accuracy</em>. Since we’re building our own <strong>BFs</strong> we can build models for <strong>raw effects</strong> too.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="choosing-priors-part-i.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="computing-bayes-factors-part-ii.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
